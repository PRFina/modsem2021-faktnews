{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import dateparser\n",
    "\n",
    "np.random.seed(1620)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"~/Desktop/data/train.tsv\")\n",
    "metadata_cols = [\"claimID\", \"claim\", \"label\", \"claimURL\",\n",
    "           \"reason\", \"categories\", \"speaker\", \"checker\", \n",
    "           \"tags\", \"articleTitle\", \"publishDate\", \"claimDate\", \"entities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev = pd.read_csv(dataset_path, sep=\"\\t\", names=metadata_cols, \n",
    "                     na_values=[\"None\",\"['None']\"], parse_dates=['publishDate','claimDate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev['publishDate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev['publishDate'].dropna().apply(dateparser.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparser.parse('Sun 8 May 2016, 7:37am')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Than marks interesting columns and delete rows that contains nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_cols = [\"articleTitle\",\"checker\",\"speaker\",\"claimDate\"] # columns subset that must not contain any null in any case\n",
    "df_rev = df_rev.dropna(subset=essential_cols) # clean NAN values\n",
    "len(df_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fill nan value for \"reason\" column with random sampled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "justifications = [\"Missing Context\",\"Deceptive Editing\", \"Malicious Transformation\"]\n",
    "new_reasons=np.random.choice(justifications,size=df_rev['reason'].isna().sum()) # generate random sample of justifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev.assign(reason=new_reasons)\n",
    "df_rev = df_rev.reset_index()\n",
    "df_rev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
