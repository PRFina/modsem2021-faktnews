{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import dateparser\n",
    "\n",
    "random_seed = np.random.seed(1620)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation: Cleaning and Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path, col_names, null_values):\n",
    "    return pd.read_csv(dataset_path, sep=\"\\t\", names=col_names, \n",
    "                     na_values=null_values)\n",
    "\n",
    "def parse_date(df, col_names, date_parser):\n",
    "    parsed_dates = df[col_names].dropna().apply(date_parser)\n",
    "    df[col_names] = pd.to_datetime(parsed_dates, errors='coerce', utc=True)\n",
    "    return df\n",
    "\n",
    "def reset_index(df):\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def drop_unnecessary_cols(df, col_names):\n",
    "    return df.drop(columns=col_names)\n",
    "\n",
    "def clean_null_values(df, col_names):\n",
    "    return df.dropna(subset=col_names) # clean NAN values\n",
    "\n",
    "def generate_random_reasons(df, reasons):\n",
    "    new_reasons=np.random.choice(reasons,size=df['reason'].isna().sum()) # generate random sample of justifications\n",
    "    df = df.assign(reason=new_reasons)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_random_offset_dates_from(df, from_col, to_col, exp_distribution_param=1.5, time_offset_unit='day'):\n",
    "    na_claim_date = df[to_col].isna() # check nan claimDate\n",
    "\n",
    "    random_sample = np.random.exponential(exp_distribution_param,size=na_claim_date.sum()) # generate random sample, with # samples == # nan values\n",
    "    day_offsets = pd.to_timedelta(random_sample, unit=time_offset_unit) # convert random sample to days offsets\n",
    "\n",
    "    new_claim_dates = df[from_col][na_claim_date] - day_offsets # generate new claimDate values from publishedDate offsetted with random days\n",
    "\n",
    "    df[to_col] = df[to_col].fillna(new_claim_dates) # replace only na claimDate values with the new generated dates\n",
    "    \n",
    "    return df\n",
    "\n",
    "def map_labels_to_rating(df, label_col, mapping):\n",
    "    df[label_col] = df[label_col].map(mapping)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def list_from_string(df, col_name):\n",
    "    df[col_name] = df[col_name].apply(lambda val: val.strip(\"[]\").replace(\"'\",'').replace('\"','').lower().split(\", \"))\n",
    "    return df\n",
    "\n",
    "def map_column_type(df, types_mapping):\n",
    "    return df.astype(types_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"train.tsv\")\n",
    "metadata_cols = [\"claimID\", \"claim\", \"label\", \"claimURL\",\n",
    "           \"reason\", \"categories\", \"speaker\", \"checker\", \n",
    "           \"tags\", \"articleTitle\", \"publishDate\", \"claimDate\", \"entities\"]\n",
    "\n",
    "mandatory_cols = [\"articleTitle\",\"checker\",\"speaker\",\"claim\",\"publishDate\",\"tags\",\"entities\"] # minimal columns subset that must not contain any null in any case\n",
    "justification_taxonomy = [\"Missing Context\",\"Deceptive Editing\", \"Malicious Transformation\"]\n",
    "\n",
    "rating_mapping = { 'false': 'False',\n",
    "                   'none': 'False',\n",
    "                   'unsupported': 'False',\n",
    "                   'no evidence': 'Mostly False',\n",
    "                   'not the whole story': 'Mostly False',\n",
    "                   'distorts the facts' : 'Mostly False',\n",
    "                   'spins the facts' : 'Mostly False',\n",
    "                   'misleading' : 'Mostly True',\n",
    "                   'cherry picks' : 'Mostly True',\n",
    "                   '': 'True'}\n",
    "\n",
    "column_type_mapping = { \"claimID\": \"string\",\n",
    "                        \"claim\": \"string\",\n",
    "                        \"label\": \"category\",\n",
    "                        \"claimURL\": \"string\",\n",
    "                        \"reason\": \"category\",\n",
    "                        \"speaker\": \"string\",\n",
    "                        \"checker\": \"string\",\n",
    "                        \"articleTitle\": \"string\"\n",
    "}\n",
    "# PIPELINE \n",
    "df = (\n",
    "    load_data(dataset_path, col_names=metadata_cols, null_values=[\"None\",\"['None']\"])\n",
    "    .pipe(drop_unnecessary_cols, ['categories'])\n",
    "    .pipe(clean_null_values, mandatory_cols)\n",
    "    .pipe(parse_date, \"publishDate\", dateparser.parse)\n",
    "    .pipe(parse_date, \"claimDate\", dateparser.parse)\n",
    "    .pipe(generate_random_reasons, reasons=justification_taxonomy) # fill reason col with fake data\n",
    "    .pipe(generate_random_offset_dates_from, from_col='publishDate', to_col='claimDate') # fill claimDate col with fake data\n",
    "    .pipe(map_labels_to_rating, label_col='label', mapping=rating_mapping) # map label column with our standard 4-values rating systems\n",
    "    .pipe(list_from_string, col_name='tags') # parse string representation of tags into an actual list of tags\n",
    "    .pipe(list_from_string, col_name='entities') # parse string representation of entities into an actual list of entities\n",
    "    .pipe(map_column_type, column_type_mapping)\n",
    "    .pipe(reset_index)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas to SQL helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_name_with_id(column):\n",
    "    values = extract_unique_values(column)\n",
    "    \n",
    "    lookup = pd.Series(pd.RangeIndex(0,len(values),1), index=values, name=column.name) # make a lookup table with tag name as key and integer id as value\n",
    "    \n",
    "    new_column =column.apply(lambda values: [lookup[val] for val in values]) # replace names with integer id\n",
    "    return new_column, lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def extract_unique_values(column):\n",
    "    if isinstance(column.dtype, pd.CategoricalDtype):\n",
    "        values = column.cat.categories.values \n",
    "    elif isinstance(column.dtype, pd.StringDtype):\n",
    "        values = set(column.values)\n",
    "    else: # for object dtype\n",
    "        values = itertools.chain.from_iterable(column.values) # extract column values from df and flatten it out\n",
    "        values = set(values) # make unique\n",
    "    return list(values)\n",
    "        \n",
    "def swap_index_with_col(df, col_name, id_col_name):\n",
    "    \"\"\"\n",
    "    swap the index of the input dataframe (df) with the col_name column.\n",
    "    This is an helper function for creating a lookup table.\n",
    "     \n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    new_df[id_col_name] = new_df.index\n",
    "    \n",
    "    return new_df.set_index(col_name)\n",
    "\n",
    "def generate_fk(fk_col, parent_table, parent_col_name):\n",
    "    \"\"\"\n",
    "    Generate a fk column looking into a lookup table.\n",
    "    The values inside fk_col are replaced with the corrisponding value index in the parent_table.\n",
    "    parent_col_name is the column in the parent table where lookup takes place.\n",
    "    \n",
    "    eg. fk_col = ['b','c','a']\n",
    "        parent_table = [[1,'a'],['2','b'],[3,'c']\n",
    "        function output is a  new fk_col = [2,3,1]\n",
    "    \"\"\"\n",
    "    id_col = 'id'\n",
    "    lookup = swap_index_with_col(parent_table, \n",
    "                                 parent_col_name,\n",
    "                                 id_col_name=id_col) # make a lookup table with parent_col_name as index and id_col as value\n",
    "    if isinstance(fk_col.dtype, pd.StringDtype):\n",
    "        new_fk_col = fk_col.apply(lambda value: lookup.loc[value,id_col]) # replace names with integer id\n",
    "    else: # for column with list-like elements\n",
    "        new_fk_col = fk_col.apply(lambda values: [lookup.loc[val,id_col] for val in values]) # replace names with integer id\n",
    "    \n",
    "    return new_fk_col\n",
    "\n",
    "def generate_joint_table(df_master, join_col, left_table, right_table, lookup_col, left_pk, right_pk):\n",
    "    \n",
    "    joint = pd.DataFrame({left_pk: left_table.index,\n",
    "                          right_pk: generate_fk(df_master[join_col],right_table, lookup_col)})\n",
    "    \n",
    "    return joint.explode(right_pk, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_table = pd.DataFrame({'label': extract_unique_values(df['tags'])})\n",
    "topic_joint_table = generate_joint_table(df, 'tags', df['claimURL'], tag_table, 'label', 'review_id', 'tag_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Entity Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_entity_table = pd.DataFrame({'label': extract_unique_values(df['entities'])})\n",
    "mention_joint_table = generate_joint_table(df, 'entities', df['claimURL'], external_entity_table, 'label', 'review_id', 'entity_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Claimants agents\n",
    "claimants = pd.DataFrame({'name': extract_unique_values(df['speaker']),\n",
    "                          'type': 'person',\n",
    "                          'role': 'claimant'\n",
    "                         })\n",
    "# some claimants are organizations\n",
    "organization_filter = claimants['name'].isin(['NRSC','Election TV Ads',\n",
    "                        'Various websites','FactCheck.org',\n",
    "                        'Viral Claim', 'National Republican Senatorial Committee',\n",
    "                        'Senate Majority PAC','Senate Leadership Fund'])\n",
    "\n",
    "claimants.loc[organization_filter ,'type'] = 'organization' # manual adjustment\n",
    "\n",
    "\n",
    "## Fact checkers agents\n",
    "factcheckers = pd.DataFrame({'name': extract_unique_values(df['checker']),\n",
    "                             'type': 'person',\n",
    "                             'role': 'factchecker'\n",
    "                         })\n",
    "# some factcheckers are organizations\n",
    "factcheckers.loc[factcheckers['name'] == 'FactCheck.org','type'] = 'organization' # manual adjustment\n",
    "\n",
    "\n",
    "## Organizations agents\n",
    "organizations = pd.DataFrame({'name': ['Pagella Politica', 'LaVoce.info','PolitiFact', \n",
    "                                       'WashingtonPost','International Fact Checking Network',\n",
    "                                       'Duke Reporter lab'],\n",
    "                              'type': 'organization',\n",
    "                              'role': 'factchecker'\n",
    "                              })\n",
    "## Software agents\n",
    "software_bots = pd.DataFrame({'name': ['DeepFakeTwitter','DistoClaim','HAL9000'],\n",
    "                              'type': 'software',\n",
    "                              'role': 'claimant'\n",
    "                              })\n",
    "\n",
    "agents = pd.concat([claimants, factcheckers, organizations, software_bots], ignore_index=True)\n",
    "\n",
    "## Generate random affiliations \n",
    "fc_organizations = agents[(agents['type'] == 'organization') & (agents['role'] == 'factchecker')]\n",
    "fc_person = agents[(agents['type'] == 'person') & (agents['role'] == 'factchecker')]\n",
    "random_affiliations_indeces = np.random.choice(fc_organizations.index, size=len(fc_person))\n",
    "\n",
    "agents.loc[fc_person.index,'affiliation_id'] = random_affiliations_indeces\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claim Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = df[['claim','speaker','claimDate','claimURL']].copy()\n",
    "\n",
    "\n",
    "claimants = agents[agents['role']=='claimant'].astype({'name':'string'}) # filter only claimant agents\n",
    "\n",
    "\n",
    "claims.loc[:,'speaker'] = generate_fk(df['speaker'], claimants, 'name') #replace names with id\n",
    "\n",
    "claims = claims.rename({'claim': 'content', #align to SQL schema\n",
    "                        'speaker': 'claimant_id',\n",
    "                        'claimDate': 'publication_date',\n",
    "                        'claimURL': 'url'}, axis='columns') # WARNING! claimURL is the review article URL, since no data is provided on the claim source url, we used this one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_systems = ['https://www.politifact.com/article/2018/feb/12/principles-truth-o-meter-politifacts-methodology-i/#Truth-O-Meter%20ratings',\n",
    "                  'https://pagellapolitica.it/static/metodologia',\n",
    "                  'https://www.lavoce.info/come-facciamo-il-fact-checking/']\n",
    "\n",
    "\n",
    "ratings = pd.DataFrame({'value': df['label'],\n",
    "                        'comment': pd.Series(dtype='string'),\n",
    "                        'media_url':'',\n",
    "                        'system_url':np.random.choice(rating_systems,size=len(df['label']))})\n",
    "\n",
    "# generate fake rating media association (only for Politifact)\n",
    "associated_media = {'False': 'https://static.politifact.com/img/meter-false.jpg',\n",
    "                    'Mostly False': 'https://static.politifact.com/img/meter-mostly-false.jpg',\n",
    "                    'Mostly True': 'https://static.politifact.com/img/meter-mostly-true.jpg',\n",
    "                    'True': 'https://static.politifact.com/img/meter-mostly-true.jpg'}\n",
    "\n",
    "politifact_mask = ratings[ratings['system_url']=='https://www.politifact.com/article/2018/feb/12/principles-truth-o-meter-politifacts-methodology-i/#Truth-O-Meter%20ratings'].index\n",
    "ratings['media_url'] = ratings.iloc[politifact_mask].apply(lambda row: associated_media[row['value']], axis='columns')\n",
    "\n",
    "# generate fake random comment \n",
    "ratings['comment'] = ratings['comment'].apply(lambda x: lorem.sentence())\n",
    "\n",
    "rating_table = ratings # just for naming consistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "liarplus_path = Path(\"LIARPlus_validation.jsonl\")\n",
    "liar_df = pd.read_json(liarplus_path, lines=True)\n",
    "# random sample justification from liar plus dataset\n",
    "# WARNING! The sampling procedure is naive, this means that no sense records could be produced\n",
    "# i.e [Missing Context, \"Donald Trump this time is completely right!\"]\n",
    "\n",
    "liarplus_justifications = (liar_df['justification'].sample(n=len(df),random_state=random_seed)\n",
    "                                                   .reset_index(drop=True))\n",
    "\n",
    "judgment_table = pd.DataFrame({'label': df['reason'],\n",
    "                               'justification': liarplus_justifications})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df[['publishDate','claimURL']].copy()\n",
    "\n",
    "reviews = reviews.rename({'publishDate': 'publication_date',\n",
    "                          'claimURL': 'url'}, axis='columns')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reviews['title'] = 'XXXX'\n",
    "reviews['content'] = 'YYYY'\n",
    "reviews['language'] = 'en'\n",
    "reviews['rating_id'] = rating_table.index\n",
    "reviews['judgment_id'] = judgment_table.index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "factcheckers = agents[agents['role']=='factchecker'].astype({'name':'string'}) # filter only factcheckers agents\n",
    "\n",
    "review_author_joint_table = generate_joint_table(df, 'checker', df['claimURL'], factcheckers, 'name', 'review_id', 'agent_id')\n",
    "about_joint_table = pd.DataFrame({'review_id': reviews.index,\n",
    "                                  'claim_id': claims.index})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile = ProfileReport(df, title='Pandas Profiling Report', explorative=True)\n",
    "#profile.to_file(\"data_cleaning_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_orig =  load_data(dataset_path, col_names=metadata_cols, null_values=[\"None\",\"['None']\"])\n",
    "#profile = ProfileReport(df_orig, title='Pandas Profiling Report', explorative=True)\n",
    "#profile.to_file(\"original_data.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malicious Transformation</td>\n",
       "      <td>\"Whether these programs are \"\"high-quality\"\" i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Missing Context</td>\n",
       "      <td>\"At the preliminary budget meeting in June 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Missing Context</td>\n",
       "      <td>\"Fresh Start PA said that under Corbett, \"\"Pen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malicious Transformation</td>\n",
       "      <td>PolitiFact agrees it is still early in the 130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malicious Transformation</td>\n",
       "      <td>There are many ways to calculate the amount th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Deceptive Editing</td>\n",
       "      <td>\"Obama was correct when he said that \"\"right n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Deceptive Editing</td>\n",
       "      <td>Such audits are due at the end of the year, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Deceptive Editing</td>\n",
       "      <td>One issue that may contribute to the confusion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Deceptive Editing</td>\n",
       "      <td>Its not all sunshine and rainbows, but it hasn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Deceptive Editing</td>\n",
       "      <td>Cheney said that the Army has only four combat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        label  \\\n",
       "0    Malicious Transformation   \n",
       "1             Missing Context   \n",
       "2             Missing Context   \n",
       "3    Malicious Transformation   \n",
       "4    Malicious Transformation   \n",
       "..                        ...   \n",
       "132         Deceptive Editing   \n",
       "133         Deceptive Editing   \n",
       "134         Deceptive Editing   \n",
       "135         Deceptive Editing   \n",
       "136         Deceptive Editing   \n",
       "\n",
       "                                         justification  \n",
       "0    \"Whether these programs are \"\"high-quality\"\" i...  \n",
       "1    \"At the preliminary budget meeting in June 200...  \n",
       "2    \"Fresh Start PA said that under Corbett, \"\"Pen...  \n",
       "3    PolitiFact agrees it is still early in the 130...  \n",
       "4    There are many ways to calculate the amount th...  \n",
       "..                                                 ...  \n",
       "132  \"Obama was correct when he said that \"\"right n...  \n",
       "133  Such audits are due at the end of the year, ne...  \n",
       "134  One issue that may contribute to the confusion...  \n",
       "135  Its not all sunshine and rainbows, but it hasn...  \n",
       "136  Cheney said that the Army has only four combat...  \n",
       "\n",
       "[137 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgment_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>claim_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     review_id  claim_id\n",
       "0            0         0\n",
       "1            1         1\n",
       "2            2         2\n",
       "3            3         3\n",
       "4            4         4\n",
       "..         ...       ...\n",
       "132        132       132\n",
       "133        133       133\n",
       "134        134       134\n",
       "135        135       135\n",
       "136        136       136\n",
       "\n",
       "[137 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "about_joint_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
