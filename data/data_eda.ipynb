{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import dateparser\n",
    "\n",
    "random_seed = np.random.seed(1620)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation: Cleaning and Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path, col_names, null_values):\n",
    "    return pd.read_csv(dataset_path, sep=\"\\t\", names=col_names, \n",
    "                     na_values=null_values)\n",
    "\n",
    "def parse_date(df, col_names, date_parser):\n",
    "    parsed_dates = df[col_names].dropna().apply(date_parser)\n",
    "    df[col_names] = pd.to_datetime(parsed_dates, errors='coerce', utc=True)\n",
    "    return df\n",
    "\n",
    "def reset_index(df):\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def drop_unnecessary_cols(df, col_names):\n",
    "    return df.drop(columns=col_names)\n",
    "\n",
    "def clean_null_values(df, col_names):\n",
    "    return df.dropna(subset=col_names) # clean NAN values\n",
    "\n",
    "def generate_random_reasons(df, reasons):\n",
    "    new_reasons=np.random.choice(reasons,size=df['reason'].isna().sum()) # generate random sample of justifications\n",
    "    df = df.assign(reason=new_reasons)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_random_offset_dates_from(df, from_col, to_col, exp_distribution_param=1.5, time_offset_unit='day'):\n",
    "    na_claim_date = df[to_col].isna() # check nan claimDate\n",
    "\n",
    "    random_sample = np.random.exponential(exp_distribution_param,size=na_claim_date.sum()) # generate random sample, with # samples == # nan values\n",
    "    day_offsets = pd.to_timedelta(random_sample, unit=time_offset_unit) # convert random sample to days offsets\n",
    "\n",
    "    new_claim_dates = df[from_col][na_claim_date] - day_offsets # generate new claimDate values from publishedDate offsetted with random days\n",
    "\n",
    "    df[to_col] = df[to_col].fillna(new_claim_dates) # replace only na claimDate values with the new generated dates\n",
    "    \n",
    "    return df\n",
    "\n",
    "def map_labels_to_rating(df, label_col, mapping):\n",
    "    df[label_col] = df[label_col].map(mapping)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def list_from_string(df, col_name):\n",
    "    df[col_name] = df[col_name].apply(lambda val: val.strip(\"[]\").replace(\"'\",'').replace('\"','').lower().split(\", \"))\n",
    "    return df\n",
    "\n",
    "def map_column_type(df, types_mapping):\n",
    "    return df.astype(types_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"train.tsv\")\n",
    "metadata_cols = [\"claimID\", \"claim\", \"label\", \"claimURL\",\n",
    "           \"reason\", \"categories\", \"speaker\", \"checker\", \n",
    "           \"tags\", \"articleTitle\", \"publishDate\", \"claimDate\", \"entities\"]\n",
    "\n",
    "mandatory_cols = [\"articleTitle\",\"checker\",\"speaker\",\"claim\",\"publishDate\",\"tags\",\"entities\"] # minimal columns subset that must not contain any null in any case\n",
    "justification_taxonomy = [\"Missing Context\",\"Deceptive Editing\", \"Malicious Transformation\"]\n",
    "\n",
    "rating_mapping = { 'false': 'False',\n",
    "                   'none': 'False',\n",
    "                   'unsupported': 'False',\n",
    "                   'no evidence': 'Mostly False',\n",
    "                   'not the whole story': 'Mostly False',\n",
    "                   'distorts the facts' : 'Mostly False',\n",
    "                   'spins the facts' : 'Mostly False',\n",
    "                   'misleading' : 'Mostly True',\n",
    "                   'cherry picks' : 'Mostly True',\n",
    "                   '': 'True'}\n",
    "\n",
    "column_type_mapping = { \"claimID\": \"string\",\n",
    "                        \"claim\": \"string\",\n",
    "                        \"label\": \"category\",\n",
    "                        \"claimURL\": \"string\",\n",
    "                        \"reason\": \"category\",\n",
    "                        \"speaker\": \"string\",\n",
    "                        \"checker\": \"string\",\n",
    "                        \"articleTitle\": \"string\"\n",
    "}\n",
    "# PIPELINE \n",
    "df = (\n",
    "    load_data(dataset_path, col_names=metadata_cols, null_values=[\"None\",\"['None']\"])\n",
    "    .pipe(drop_unnecessary_cols, ['categories'])\n",
    "    .pipe(clean_null_values, mandatory_cols)\n",
    "    .pipe(parse_date, \"publishDate\", dateparser.parse)\n",
    "    .pipe(parse_date, \"claimDate\", dateparser.parse)\n",
    "    .pipe(generate_random_reasons, reasons=justification_taxonomy) # fill reason col with fake data\n",
    "    .pipe(generate_random_offset_dates_from, from_col='publishDate', to_col='claimDate') # fill claimDate col with fake data\n",
    "    .pipe(map_labels_to_rating, label_col='label', mapping=rating_mapping) # map label column with our standard 4-values rating systems\n",
    "    .pipe(list_from_string, col_name='tags') # parse string representation of tags into an actual list of tags\n",
    "    .pipe(list_from_string, col_name='entities') # parse string representation of entities into an actual list of entities\n",
    "    .pipe(map_column_type, column_type_mapping)\n",
    "    .pipe(reset_index)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas to SQL helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def extract_unique_values(column):\n",
    "    if isinstance(column.dtype, pd.CategoricalDtype):\n",
    "        values = column.cat.categories.values \n",
    "    elif isinstance(column.dtype, pd.StringDtype):\n",
    "        values = set(column.values)\n",
    "    else: # for object dtype\n",
    "        values = itertools.chain.from_iterable(column.values) # extract column values from df and flatten it out\n",
    "        values = set(values) # make unique\n",
    "    return list(values)\n",
    "        \n",
    "def swap_index_with_col(df, col_name, id_col_name):\n",
    "    \"\"\"\n",
    "    swap the index of the input dataframe (df) with the col_name column.\n",
    "    This is an helper function for creating a lookup table.\n",
    "     \n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    new_df[id_col_name] = new_df.index\n",
    "    \n",
    "    return new_df.set_index(col_name)\n",
    "\n",
    "def generate_fk(fk_col, parent_table, parent_col_name):\n",
    "    \"\"\"\n",
    "    Generate a fk column looking into a lookup table.\n",
    "    The values inside fk_col are replaced with the corrisponding value index in the parent_table.\n",
    "    parent_col_name is the column in the parent table where lookup takes place.\n",
    "    \n",
    "    eg. fk_col = ['b','c','a']\n",
    "        parent_table = [[1,'a'],['2','b'],[3,'c']\n",
    "        function output is a  new fk_col = [2,3,1]\n",
    "    \"\"\"\n",
    "    id_col = 'id'\n",
    "    lookup = swap_index_with_col(parent_table, \n",
    "                                 parent_col_name,\n",
    "                                 id_col_name=id_col) # make a lookup table with parent_col_name as index and id_col as value\n",
    "    if isinstance(fk_col.dtype, pd.StringDtype):\n",
    "        new_fk_col = fk_col.apply(lambda value: lookup.loc[value,id_col]) # replace names with integer id\n",
    "    else: # for column with list-like elements\n",
    "        new_fk_col = fk_col.apply(lambda values: [lookup.loc[val,id_col] for val in values]) # replace names with integer id\n",
    "    \n",
    "    return new_fk_col\n",
    "\n",
    "def generate_joint_table(df_master, join_col, left_table, right_table, lookup_col, left_pk, right_pk):\n",
    "    \n",
    "    joint = pd.DataFrame({left_pk: left_table.index,\n",
    "                          right_pk: generate_fk(df_master[join_col],right_table, lookup_col)})\n",
    "    \n",
    "    return joint.explode(right_pk, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_table = pd.DataFrame({'label': extract_unique_values(df['tags'])})\n",
    "topic_joint_table = generate_joint_table(df, 'tags', df['claimURL'], tag_table, 'label', 'review_id', 'tag_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Entity Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_entity_table = pd.DataFrame({'label': extract_unique_values(df['entities'])})\n",
    "mention_joint_table = generate_joint_table(df, 'entities', df['claimURL'], external_entity_table, 'label', 'review_id', 'entity_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Claimants agents\n",
    "claimants = pd.DataFrame({'name': extract_unique_values(df['speaker']),\n",
    "                          'type': 'person',\n",
    "                          'role': 'claimant'\n",
    "                         })\n",
    "# some claimants are organizations\n",
    "organization_filter = claimants['name'].isin(['NRSC','Election TV Ads',\n",
    "                        'Various websites','FactCheck.org',\n",
    "                        'Viral Claim', 'National Republican Senatorial Committee',\n",
    "                        'Senate Majority PAC','Senate Leadership Fund'])\n",
    "\n",
    "claimants.loc[organization_filter ,'type'] = 'organization' # manual adjustment\n",
    "\n",
    "\n",
    "## Fact checkers agents\n",
    "factcheckers = pd.DataFrame({'name': extract_unique_values(df['checker']),\n",
    "                             'type': 'person',\n",
    "                             'role': 'factchecker'\n",
    "                         })\n",
    "\n",
    "# remove FactCheck.org row because is inserted after with organization group\n",
    "mask = factcheckers.loc[factcheckers['name'] == 'FactCheck.org'].index\n",
    "factcheckers.drop(mask)\n",
    "\n",
    "\n",
    "## Organizations agents\n",
    "organizations = pd.DataFrame({'name': ['FactCheck.org','Pagella Politica', 'LaVoce.info','PolitiFact', \n",
    "                                       'WashingtonPost','International Fact Checking Network',\n",
    "                                       'Duke Reporter lab'],\n",
    "                              'type': 'organization',\n",
    "                              'role': 'factchecker'\n",
    "                              })\n",
    "## Software agents\n",
    "software_bots = pd.DataFrame({'name': ['DeepFakeTwitter','DistoClaim','HAL9000'],\n",
    "                              'type': 'software',\n",
    "                              'role': 'claimant'\n",
    "                              })\n",
    "# organization MUST be inserted before factchecker due to self referential foreign key\n",
    "agents = pd.concat([organizations, claimants, factcheckers, software_bots], ignore_index=True)\n",
    "\n",
    "## Generate random affiliations \n",
    "fc_organizations = agents[(agents['type'] == 'organization') & (agents['role'] == 'factchecker')]\n",
    "fc_person = agents[(agents['type'] == 'person') & (agents['role'] == 'factchecker')]\n",
    "random_affiliations_indeces = np.random.choice(fc_organizations.index, size=len(fc_person))\n",
    "\n",
    "agents.loc[fc_person.index,'affiliation_id'] = random_affiliations_indeces\n",
    "\n",
    "agent_table = agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claim Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = df[['claim','speaker','claimDate','claimURL']].copy()\n",
    "\n",
    "\n",
    "claimants = agents[agents['role']=='claimant'].astype({'name':'string'}) # filter only claimant agents\n",
    "\n",
    "\n",
    "claims.loc[:,'speaker'] = generate_fk(df['speaker'], claimants, 'name') #replace names with id\n",
    "claims['language'] = 'en'\n",
    "claims = claims.rename({'claim': 'content', #align to SQL schema\n",
    "                        'speaker': 'claimant_id',\n",
    "                        'claimDate': 'publication_date',\n",
    "                        'claimURL': 'url'}, axis='columns') # WARNING! claimURL is the review article URL, since no data is provided on the claim source url, we used this one\n",
    "\n",
    "claim_table = claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_systems = ['https://www.politifact.com/article/2018/feb/12/principles-truth-o-meter-politifacts-methodology-i/#Truth-O-Meter%20ratings',\n",
    "                  'https://pagellapolitica.it/static/metodologia',\n",
    "                  'https://www.lavoce.info/come-facciamo-il-fact-checking/']\n",
    "\n",
    "\n",
    "ratings = pd.DataFrame({'value': df['label'],\n",
    "                        'comment': pd.Series(dtype='string'),\n",
    "                        'media_url':'',\n",
    "                        'system_url':np.random.choice(rating_systems,size=len(df['label']))})\n",
    "\n",
    "# generate fake rating media association (only for Politifact)\n",
    "associated_media = {'False': 'https://static.politifact.com/img/meter-false.jpg',\n",
    "                    'Mostly False': 'https://static.politifact.com/img/meter-mostly-false.jpg',\n",
    "                    'Mostly True': 'https://static.politifact.com/img/meter-mostly-true.jpg',\n",
    "                    'True': 'https://static.politifact.com/img/meter-mostly-true.jpg'}\n",
    "\n",
    "politifact_mask = ratings[ratings['system_url']=='https://www.politifact.com/article/2018/feb/12/principles-truth-o-meter-politifacts-methodology-i/#Truth-O-Meter%20ratings'].index\n",
    "ratings['media_url'] = ratings.iloc[politifact_mask].apply(lambda row: associated_media[row['value']], axis='columns')\n",
    "\n",
    "# generate fake random comment \n",
    "ratings['comment'] = ratings['comment'].apply(lambda x: lorem.sentence())\n",
    "\n",
    "rating_table = ratings # just for naming consistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liarplus_path = Path(\"LIARPlus_validation.jsonl\")\n",
    "liar_df = pd.read_json(liarplus_path, lines=True)\n",
    "# random sample justification from liar plus dataset\n",
    "# WARNING! The sampling procedure is naive, this means that no sense records could be produced\n",
    "# i.e [Missing Context, \"Donald Trump this time is completely right!\"]\n",
    "\n",
    "liarplus_justifications = (liar_df['justification'].sample(n=len(df),random_state=random_seed)\n",
    "                                                   .reset_index(drop=True))\n",
    "\n",
    "judgment_table = pd.DataFrame({'label': df['reason'],\n",
    "                               'justification': liarplus_justifications})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df[['publishDate','claimURL']].copy()\n",
    "\n",
    "reviews = reviews.rename({'publishDate': 'publication_date',\n",
    "                          'claimURL': 'url'}, axis='columns')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reviews['title'] = 'XXXX'\n",
    "reviews['content'] = 'YYYY'\n",
    "reviews['language'] = 'en'\n",
    "reviews['rating_id'] = rating_table.index\n",
    "reviews['judgment_id'] = judgment_table.index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "factcheckers = agents[agents['role']=='factchecker'].astype({'name':'string'}) # filter only factcheckers agents\n",
    "\n",
    "review_author_joint_table = generate_joint_table(df, 'checker', df['claimURL'], factcheckers, 'name', 'review_id', 'agent_id')\n",
    "about_joint_table = pd.DataFrame({'review_id': reviews.index,\n",
    "                                  'claim_id': claims.index})\n",
    "\n",
    "\n",
    "\n",
    "review_table = reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile = ProfileReport(df, title='Pandas Profiling Report', explorative=True)\n",
    "#profile.to_file(\"data_cleaning_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_orig =  load_data(dataset_path, col_names=metadata_cols, null_values=[\"None\",\"['None']\"])\n",
    "#profile = ProfileReport(df_orig, title='Pandas Profiling Report', explorative=True)\n",
    "#profile.to_file(\"original_data.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert Into RDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from psycopg2.extensions import register_adapter, AsIs\n",
    "\n",
    "register_adapter(np.int64, AsIs)\n",
    "\n",
    "engine = create_engine(\"postgresql://{username}:{password}@{host}:{port}/{database}\".format(username='modsem',\n",
    "                                                                                            password='modsem',\n",
    "                                                                                            host='localhost',\n",
    "                                                                                            port=5432,\n",
    "                                                                                            database='faktnews'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_table.to_sql('tag',con=engine, if_exists='append', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_table.to_sql('rating',con=engine, if_exists='append', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judgment_table.to_sql('judgment',con=engine, if_exists='append', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_table.to_sql('review',con=engine, if_exists='append', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_table.to_sql('agent',con=engine, if_exists='append', index_label='id',method=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_table.to_sql('claim',con=engine, if_exists='append', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_entity_table.to_sql('external_entity',con=engine, if_exists='append', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_joint_table.to_sql('topic',con=engine, if_exists='append', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_joint_table.to_sql('mention',con=engine, if_exists='append', index_label='id')\n",
    "review_author_joint_table.to_sql('review_author',con=engine, if_exists='append', index_label='id')\n",
    "about_joint_table.to_sql('about',con=engine, if_exists='append', index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
